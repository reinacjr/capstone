{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b347a634-ca79-4bb7-b049-e49b00704a42",
   "metadata": {},
   "source": [
    "## Log Standardisation and Extraction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd0faa-7f59-4496-8090-2fb01b102caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aeed34-ebad-4d36-9855-87e69a83ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== STEP 1: Load Files ===\n",
    "\n",
    "#Load desired fields and manual input flags from Excel\n",
    "field_df = pd.read_excel(\"Data Extraction Fields.xlsx\", header=None)\n",
    "field_df.columns = [\"Field Name\", \"Manual Input\"]\n",
    "field_df[\"Field Name\"] = field_df[\"Field Name\"].str.strip()\n",
    "field_df[\"Manual Input\"] = field_df[\"Manual Input\"].fillna(\"\").astype(str).str.lower()\n",
    "\n",
    "#Get field names and manual input fields\n",
    "desired_fields = field_df[\"Field Name\"].tolist()\n",
    "manual_fields = field_df[field_df[\"Manual Input\"].isin([\"yes\", \"true\", \"manual\"])][\"Field Name\"].tolist()\n",
    "\n",
    "#Load planned test cases CSV\n",
    "planned_df = pd.read_csv(\"refined_security_test_cases.csv\")\n",
    "\n",
    "#Read and split log file\n",
    "with open(\"updated_logs.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    log_blocks = f.read().split(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f073d-b611-4eb7-a57d-c9c85f15ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== STEP 2: Parse Logs in Pairs ===\n",
    "\n",
    "parsed_logs = []\n",
    "i = 0\n",
    "while i < len(log_blocks) - 1:\n",
    "    req = log_blocks[i].strip()\n",
    "    res = log_blocks[i + 1].strip()\n",
    "    i += 2\n",
    "\n",
    "    entry = {\n",
    "        \"Date of Test Executed\": \"\",\n",
    "        \"Project ID\": \"\",\n",
    "        \"User ID\": \"\",\n",
    "        \"Test Case ID\": \"\",\n",
    "        \"User Agent\": \"\",\n",
    "        \"Request Method\": \"\",\n",
    "        \"Requested Source\": \"\",\n",
    "        \"Test Case Outcome Message\": \"\",\n",
    "        \"Error Message\": \"\",\n",
    "        \"Response Size\": \"\"\n",
    "    }\n",
    "\n",
    "    #Parse request block\n",
    "    for line in req.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if re.match(r\"^(GET|POST|PUT|DELETE|HEAD|OPTIONS|PATCH)\", line):\n",
    "            parts = line.split()\n",
    "            entry[\"Request Method\"] = parts[0]\n",
    "            entry[\"Requested Source\"] = parts[1]\n",
    "        elif \"User-Agent:\" in line:\n",
    "            entry[\"User Agent\"] = line.split(\"User-Agent:\")[-1].strip()\n",
    "        elif \"Project ID:\" in line:\n",
    "            entry[\"Project ID\"] = line.split(\"Project ID:\")[-1].strip()\n",
    "        elif \"User ID:\" in line:\n",
    "            entry[\"User ID\"] = line.split(\"User ID:\")[-1].strip()\n",
    "        elif \"Test Case ID:\" in line:\n",
    "            entry[\"Test Case ID\"] = line.split(\"Test Case ID:\")[-1].strip()\n",
    "\n",
    "    #Parse response block\n",
    "    for line in res.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"HTTP\"):\n",
    "            entry[\"Test Case Outcome Message\"] = \"Pass\" if \"200 OK\" in line else \"Fail\"\n",
    "            entry[\"Error Message\"] = \"\" if \"200 OK\" in line else line\n",
    "        elif line.lower().startswith(\"date:\"):\n",
    "            raw_date = line.split(\":\", 1)[-1].strip()\n",
    "            try:\n",
    "                parsed_date = datetime.strptime(raw_date, \"%a, %d %b %Y %H:%M:%S %Z\")\n",
    "                entry[\"Date of Test Executed\"] = parsed_date.strftime(\"%d/%m/%Y\")\n",
    "            except Exception:\n",
    "                entry[\"Date of Test Executed\"] = raw_date\n",
    "        elif \"Content-Length:\" in line:\n",
    "            entry[\"Response Size\"] = line.split(\"Content-Length:\")[-1].strip()\n",
    "\n",
    "    #Append only if key fields exist\n",
    "    if entry[\"Project ID\"] and entry[\"User ID\"] and entry[\"Test Case ID\"]:\n",
    "        parsed_logs.append(entry)\n",
    "\n",
    "logs_df = pd.DataFrame(parsed_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9906227-442e-4c29-a34e-898041dfefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== STEP 3: Merge with Planned Test Cases ===\n",
    "\n",
    "merged_df = pd.merge(planned_df, logs_df, on=[\"Project ID\", \"User ID\", \"Test Case ID\"], how=\"left\")\n",
    "\n",
    "#Format Deadline field if it exists\n",
    "if \"Deadline\" in merged_df.columns:\n",
    "    try:\n",
    "        merged_df[\"Deadline\"] = pd.to_datetime(merged_df[\"Deadline\"], errors='coerce').dt.strftime(\"%d/%m/%Y\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "#Dynamically generate Test Case Status\n",
    "merged_df[\"Test Case Status\"] = merged_df.apply(\n",
    "    lambda row: \"Completed\" if pd.notna(row[\"Date of Test Executed\"]) else \"Not Started\", axis=1\n",
    ")\n",
    "\n",
    "#=== STEP 4: Add Blank Manual Input Columns ===\n",
    "for col in manual_fields:\n",
    "    if col not in merged_df.columns:\n",
    "        merged_df[col] = \"\"\n",
    "\n",
    "#=== STEP 5: Align Final Output Columns ===\n",
    "\n",
    "#Normalise columns to lowercase for safe matching\n",
    "merged_df.columns = [col.lower().strip() for col in merged_df.columns]\n",
    "final_cols_lower = [col.lower().strip() for col in desired_fields]\n",
    "\n",
    "#Ensure all desired fields exist\n",
    "for col in final_cols_lower:\n",
    "    if col not in merged_df.columns:\n",
    "        merged_df[col] = \"\"\n",
    "\n",
    "#Reorder and restore headers\n",
    "final_output = merged_df[final_cols_lower]\n",
    "final_output.columns = desired_fields  #Restore original header casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb1622-ef9d-4b0d-b603-5076b999dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== STEP 6: Export to CSV ===\n",
    "final_output.to_csv(\"logs_system_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
